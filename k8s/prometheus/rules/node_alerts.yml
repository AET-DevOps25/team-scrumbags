groups:
  - name: node_alerts
    rules:
      - alert: HighCPULoad
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "High CPU load (instance {{ $labels.instance }})"
          description: "CPU load is > 80%\n  VALUE = {{ $value }}%\n  LABELS: {{ $labels }}"

      - alert: HighMemoryLoad
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 80
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "High memory load (instance {{ $labels.instance }})"
          description: "Memory load is > 80%\n  VALUE = {{ $value }}%\n  LABELS: {{ $labels }}"

      - alert: HighDiskUsage
        expr: (node_filesystem_size_bytes{fstype=~"ext4|xfs"} - node_filesystem_free_bytes{fstype=~"ext4|xfs"}) / node_filesystem_size_bytes{fstype=~"ext4|xfs"} * 100 > 85
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "High disk usage (instance {{ $labels.instance }})"
          description: "Disk usage is > 85%\n  VALUE = {{ $value }}%\n  LABELS: {{ $labels }}"

#  - name: test_alerts
#    rules:
#      - alert: AlwaysFiring
#        expr: vector(1)
#        for: 0m
#        labels:
#          severity: test
#        annotations:
#          summary: "Test alert - always firing"
#          description: "This alert should always be active for testing purposes"
#
#      - alert: PrometheusUp
#        expr: up{job="prometheus"} == 1
#        for: 0m
#        labels:
#          severity: info
#        annotations:
#          summary: "Prometheus is up"
#          description: "Prometheus instance is running"
#
#      - alert: ProgramStarted
#        expr: up == 1
#        for: 0m
#        labels:
#          severity: test
#        annotations:
#          summary: "Yet another test alert"
#          description: "Last test alert for now, hopefully."